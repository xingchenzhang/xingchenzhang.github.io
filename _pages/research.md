---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---
{% include base_path %}

Vision
----

My Fusion Intelligence Laboratory aims to **use machine intelligence and multi-source information fusion to benefit humanity.**


Research areas
----
My research areas include
   
- Computer vision (e.g., object tracking, human pose estimation, human behavior prediction)   
- Deep learning (e.g., multi-modal learning, self-supervised learning, graph-based learning)  
- Image fusion (visible-infrared, multi-focus, multi-exposure, multimodal medical images)  
- Multimodal applications (e.g., RGB-T tracking, RGB-T segmentation, RGB-T crowd counting)  
- Robotics and AI (e.g., Robot perception)
- Ethical AI (pedestrian privacy protection)
- AI for Science   

Some funded projects
----

- Exeter-Fudan Fellowship
- The Royal Society Research Grant  
- Marie-Curie Individual Fellowship
- Shanghai Science and Technology Committee Research Project

Research topics
----

<h2>1. Deep Learning-based image fusion: methods, benchmarks, and multi-modal applications</h2>

<div style="display: flex; justify-content: center; align-items: center;">
  <img src="/images/research/vif.png" alt="First Image" style="height: 300px; width: auto; margin-right: 20px;">
  <img src="/images/research/mef.png" alt="Second Image" style="height: 300px; width: auto;">
</div>

Related publications:  
1. **X. Zhang**, Y. Demiris. Visible and Infrared Image Fusion using Deep Learning, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 45, no. 8, pp. 10535-10554, 2023. (**ESI Highly Cited Paper)**  
2. **X. Zhang**. Deep Learning-based Multi-focus Image Fusion: A Survey and A Comparative Study, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 44, No. 9, pp. 4819 – 4838, 2022. [[Link]](https://github.com/xingchenzhang/MFIFB) (**ESI Highly Cited Paper**)  
3. **X. Zhang**. Benchmarking and Comparing Multi-exposure Image Fusion Algorithms. Information Fusion, vol. 74, pp. 111-131, 2021. (The first multi-exposure image fusion benchmark) [[Benchmark link]](https://github.com/xingchenzhang/MEFB)  
4. **X. Zhang**, P. Ye, G. Xiao. VIFB: A Visible and Infrared Image Fusion Benchmark, In the Proceedings of IEEE/CVF Conference on Computer Vision Workshops, 2020. (The first image fusion benchmark, which has been utilized by researchers from more than 10 countries.) [[Benchmark link]](https://github.com/xingchenzhang/VIFB)  
5. **X. Zhang**, P. Ye, S. Peng, J. Liu, G. Xiao. DSiamMFT: An RGB-T fusion tracking method via
dynamic Siamese networks using multi-layer feature fusion. Signal Processing: Image
Communication, vol. 84, 2020.  
6. **X. Zhang**, P. Ye, D. Qiao, J. Zhao, S. Peng, G. Xiao. Object Fusion Tracking Based on Visible and
Infrared Images Using Fully Convolutional Siamese Networks. In Proceedings of the 22nd
International Conference on Information Fusion, 2019.  
7. **X. Zhang**. "Multi-focus image fusion: A benchmark." arXiv preprint arXiv:2005.01116 (2020). (The first multi-focus image fusion benchmark in the community)  
8. Z. Zhao, A. Howes, **X. Zhang**\*. MultiTaskVIF: Segmentation-oriented visible and infrared image fusion via multi-task learning. arXiv preprint arXiv:2505.06665. [[Link]](https://arxiv.org/pdf/2505.06665)

<h2>2. Human-centered computer vision</h2>
<h3>(1) Pedestrian trajectory prediction based on graph neural network</h3>
<p align="center"> 
  <img width="500" src="/images/research/Demo Social TAG.gif" />
</p>

<h3>(2) Pedestrian crossing intention prediction based on graph neural network</h3>
<p align="center"> 
  <img width="700" src="/images/research/crossingpose.png" />
</p>

<h3>(3) Pedestrian tracking</h3>
<p align="center"> 
  <img width="700" src="/images/research/Pedestrian-tracking.gif" />
</p>

<h3>(4) Crowd counting</h3>
<p align="center"> 
  <img width="500" src="/images/research/crowd-counting.jpg" />
</p>

Related publications:    
1. **X. Zhang***, P. Angeloudis, Y. Demiris. Dual-branch Spatio-Temporal Graph Neural Networks for Pedestrian Trajectory Prediction, Pattern Recognition, vol. 142, 2023.    
2. **X. Zhang***, P. Angeloudis, Y. Demiris. ST CrossingPose: A Spatial-Temporal Graph Convolutional Network for Skeleton-based Pedestrian Crossing Intention Prediction, IEEE Transactions on Intelligent Transportations, vol. 23, no. 11, pp. 20773-20782, 2022.  

\* Corresponding authors

<h2>3. Responsible and ethical AI: Pedestrian privacy protection</h2>
Many videos are captured to train AI models. We aim to protect pedestrian privacy in videos captured by cameras mounted on robots and vehicles while maintaining the utility of the anonymized videos.

<!-- <img align="center" width="600" src="/images/word cloud.png" />  -->

<!-- 
<p align="center"> 
  <img width="600" src="/images/research/3PFS.png" />
</p>
-->

<div style="display: flex; justify-content: center; align-items: center;">
  <img src="/images/research/3PFS.png" alt="First Image" style="height: 300px; width: auto; margin-right: 20px;">
  <img src="/images/research/3PFS.gif" alt="Second Image" style="height: 300px; width: auto;">
</div>

Related publications:  
1. Z. Zhao, **X. Zhang***, Y. Demiris. 3PFS: Protecting pedestrian privacy through face swapping, IEEE Transactions on Intelligent Transportation Systems, vol. 25, no. 11, pp. 16845-16854, 2024.

<h2>4. Computer vision</h2>
<p align="center"> 
  <img width="800" src="/images/research/tracking.png" />
</p>

Related publications:  
1. J. Liu, P. Ye. **X. Zhang***, G. Xiao. Real-time long-term tracking with reliability assessment and
object recovery. IET Image Processing, vol. 15, no. 4, pp. 918-935, 2021.  
2. J. Liu, G. Xiao, **X. Zhang***, P. Ye, X. Xiong, S. Peng. Anti-occlusion object tracking based on
correlation filter. Signal, Image and Video Processing, vol. 14, no. 4, pp. 753-761, 2020.  
3. J. Zhao, G. Xiao\*, **X. Zhang***, D. P. Bavirisetti. An improved long-term correlation tracking method with occlusion handling. Chinese Optics Letters, vol. 17, no. 3, pp. 031001-1: 031001-6, 2019.   
4. **X. Zhang**\*, Y. Demiris. Self-Supervised RGB-T Tracking with Cross-Input Consistency. arXiv preprint arXiv:2301.11274 (2023).  
5. H. Li, Z. Wang, W. Kong, **X. Zhang**\*. SelectMOT: Improving Data Association in Multiple Object Tracking via Quality-Aware Bounding Box Selection. IEEE Sensors Journal, 2025. 

<h2>5. Robotics and AI, especially robot perception</h2>
<div style="display: flex; justify-content: center; align-items: center;">
  <img src="/images/research/dog_video1.gif" alt="First Image" style="height: 350px; width: auto; margin-right: 20px;">
  <img src="/images/research/dog_video2.gif" alt="Second Image" style="height: 350px; width: auto;">
</div>


<h2>6. AI, e.g., AI security, AI safety, AI for Social Good</h2>
Ongoing collaborative projects.

<p align="center"> 
  <img width="500" src="/images/research/BGM-IJCAI2025.png" />
</p>

Related publications:  
1. Y. Zhao, H. Wen, **X. Zhang**, M. Luo. BGM: Demand Prediction for Expanding Bike-Sharing Systems with Dynamic Graph Modeling， IJCAI2025.


<h2>7. AI for Science</h2>
Ongoing collaborative projects.